一个人工智能学习任务的核心是模型的定义和模型的参数求解方式。对这两者进行抽象之后，可以确定一个唯一的计算逻辑，将这个逻辑用图表示，就叫计算图。神经网络的计算是由前向传播和反向传播构成的，先通过前向传播计算预测结果和损失，然后通过反向传播计算损失函数关于(w, b)的偏导数，并对这些参数进行梯度下降，然后通过新的参数进行新一轮的计算。

$z=w_{1} x_{1}+w_{2} x_{2}+b \rightarrow a=\sigma(z) \rightarrow \mathcal{L}(a, y)$

- 前向传播：通过上面公式计算出损失函数 L
- 反向传播：计算出 dw1 dw2 db (L相对于 w1 w2 b 的偏导数)
- 梯度下降：$`\mathrm{w}_1^{\prime}=\mathrm{w}_1-\mathrm{r}^{\star}\mathrm{d}\mathrm{w}_1`$

重复上述过程进行下一轮训练。
